{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-14T21:39:49.437238Z",
     "start_time": "2025-06-14T21:39:49.131641Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Suppress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_safe_tags' from 'sklearn.utils._tags' (C:\\Users\\josep\\OneDrive\\Desktop\\Software\\RedditProblemFinder\\.venv\\Lib\\site-packages\\sklearn\\utils\\_tags.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[59]\u001B[39m\u001B[32m, line 8\u001B[39m\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmodel_selection\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmetrics\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m accuracy_score, classification_report\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mimblearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mover_sampling\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SMOTE\n\u001B[32m      9\u001B[39m \u001B[38;5;66;03m# Suppress Warnings\u001B[39;00m\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mwarnings\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Software\\RedditProblemFinder\\.venv\\Lib\\site-packages\\imblearn\\__init__.py:52\u001B[39m\n\u001B[32m     48\u001B[39m     sys.stderr.write(\u001B[33m\"\u001B[39m\u001B[33mPartial import of imblearn during the build process.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     49\u001B[39m     \u001B[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001B[39;00m\n\u001B[32m     50\u001B[39m     \u001B[38;5;66;03m# process, as it may not be compiled yet\u001B[39;00m\n\u001B[32m     51\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m52\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     53\u001B[39m         combine,\n\u001B[32m     54\u001B[39m         ensemble,\n\u001B[32m     55\u001B[39m         exceptions,\n\u001B[32m     56\u001B[39m         metrics,\n\u001B[32m     57\u001B[39m         over_sampling,\n\u001B[32m     58\u001B[39m         pipeline,\n\u001B[32m     59\u001B[39m         tensorflow,\n\u001B[32m     60\u001B[39m         under_sampling,\n\u001B[32m     61\u001B[39m         utils,\n\u001B[32m     62\u001B[39m     )\n\u001B[32m     63\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_version\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m __version__\n\u001B[32m     64\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbase\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m FunctionSampler\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Software\\RedditProblemFinder\\.venv\\Lib\\site-packages\\imblearn\\ensemble\\__init__.py:7\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[33;03mThe :mod:`imblearn.ensemble` module include methods generating\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[33;03munder-sampled subsets combined inside an ensemble.\u001B[39;00m\n\u001B[32m      4\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_bagging\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BalancedBaggingClassifier\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_easy_ensemble\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m EasyEnsembleClassifier\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_forest\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BalancedRandomForestClassifier\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_weight_boosting\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m RUSBoostClassifier\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Software\\RedditProblemFinder\\.venv\\Lib\\site-packages\\imblearn\\ensemble\\_easy_ensemble.py:16\u001B[39m\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mensemble\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_base\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _partition_estimators\n\u001B[32m     15\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_param_validation\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Interval, StrOptions\n\u001B[32m---> \u001B[39m\u001B[32m16\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_tags\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _safe_tags\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfixes\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m parse_version\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmetaestimators\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m available_if\n",
      "\u001B[31mImportError\u001B[39m: cannot import name '_safe_tags' from 'sklearn.utils._tags' (C:\\Users\\josep\\OneDrive\\Desktop\\Software\\RedditProblemFinder\\.venv\\Lib\\site-packages\\sklearn\\utils\\_tags.py)"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T02:21:46.404614Z",
     "start_time": "2025-06-14T02:21:46.386655Z"
    }
   },
   "cell_type": "code",
   "source": "data = pd.read_csv('../data/labeled_cleaned_data.csv')",
   "id": "aa6eba15bea03338",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T02:21:46.999442Z",
     "start_time": "2025-06-14T02:21:46.422106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "model = AutoModel.from_pretrained('bert-base-cased').to(device)"
   ],
   "id": "ae9bbf713570f838",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T02:21:47.017211Z",
     "start_time": "2025-06-14T02:21:47.014643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_bert_sentence_embedding(text):\n",
    "    if pd.isna(text) or not isinstance(text, str) or text.strip() == \"\":\n",
    "        return np.zeros(model.config.hidden_size, dtype=np.float32)\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    sentence_embedding = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n",
    "    return sentence_embedding"
   ],
   "id": "c980ae99a0452b05",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T02:22:45.564527Z",
     "start_time": "2025-06-14T02:21:47.041537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data['title'] = data['title'].apply(lambda x: get_bert_sentence_embedding(x))\n",
    "data['body'] = data['body'].apply(lambda x: get_bert_sentence_embedding(x))"
   ],
   "id": "812bb83311f81b27",
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAxisError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[34]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m data[\u001B[33m'\u001B[39m\u001B[33mtitle\u001B[39m\u001B[33m'\u001B[39m] = data[\u001B[33m'\u001B[39m\u001B[33mtitle\u001B[39m\u001B[33m'\u001B[39m].apply(\u001B[38;5;28;01mlambda\u001B[39;00m x: get_bert_sentence_embedding(x))\n\u001B[32m      2\u001B[39m data[\u001B[33m'\u001B[39m\u001B[33mbody\u001B[39m\u001B[33m'\u001B[39m] = data[\u001B[33m'\u001B[39m\u001B[33mbody\u001B[39m\u001B[33m'\u001B[39m].apply(\u001B[38;5;28;01mlambda\u001B[39;00m x: get_bert_sentence_embedding(x))\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m combined = \u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtitle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbody\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m combined.shape\n",
      "\u001B[31mAxisError\u001B[39m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T02:30:29.613204Z",
     "start_time": "2025-06-14T02:30:29.608949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "title_emb = np.stack(data.title.values)\n",
    "body_emb = np.stack(data.body.values)\n",
    "combined = np.concatenate([title_emb, body_emb], axis=1)"
   ],
   "id": "4108096499c7741",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T02:31:14.388343Z",
     "start_time": "2025-06-14T02:31:14.383182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "combined = pd.DataFrame(combined, columns=[f'bert_emb_{i}' for i in range(combined.shape[1])])\n",
    "data_clean = data.drop(columns=['title', 'body'])  # drop embeddings stored in these two columns\n",
    "data_combined = pd.concat([data_clean.reset_index(drop=True), combined], axis=1)"
   ],
   "id": "85dce2eefc06d825",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T02:31:23.459149Z",
     "start_time": "2025-06-14T02:31:23.450889Z"
    }
   },
   "cell_type": "code",
   "source": "data_combined",
   "id": "76515da8d1d5a6ee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     score  num_comments  upvote_ratio   created_utc  total_awards_received  \\\n",
       "0        0            10          0.23  1.747252e+09                      0   \n",
       "1        2             1          1.00  1.747258e+09                      0   \n",
       "2        2             0          1.00  1.747142e+09                      0   \n",
       "3       12            11          1.00  1.747235e+09                      0   \n",
       "4        1             3          1.00  1.746760e+09                      0   \n",
       "..     ...           ...           ...           ...                    ...   \n",
       "493      2             1          1.00  1.747264e+09                      0   \n",
       "494      1             0          1.00  1.747254e+09                      0   \n",
       "495      1             0          1.00  1.747266e+09                      0   \n",
       "496      6             6          0.88  1.747252e+09                      0   \n",
       "497      3             2          1.00  1.747252e+09                      0   \n",
       "\n",
       "     title_length  body_length  title_word_count  body_word_count  \\\n",
       "0              23         1089                 5              190   \n",
       "1              81         1341                11              183   \n",
       "2              97         5252                15              773   \n",
       "3              52         4172                10              656   \n",
       "4              77         3435                14              616   \n",
       "..            ...          ...               ...              ...   \n",
       "493            36          673                 7               96   \n",
       "494            44         1328                 6              218   \n",
       "495            31          468                 5               86   \n",
       "496            17          250                 3               46   \n",
       "497            39         1925                 9              339   \n",
       "\n",
       "     has_question_mark  ...  bert_emb_1526  bert_emb_1527  bert_emb_1528  \\\n",
       "0                    1  ...       0.327762       0.357278      -0.220949   \n",
       "1                    0  ...       0.419177       0.331732      -0.333891   \n",
       "2                    1  ...       0.524374       0.305135      -0.026640   \n",
       "3                    0  ...       0.573908       0.084166      -0.433981   \n",
       "4                    1  ...       0.487628       0.455405      -0.368931   \n",
       "..                 ...  ...            ...            ...            ...   \n",
       "493                  1  ...       0.449083       0.395922      -0.337725   \n",
       "494                  0  ...       0.477509       0.172439      -0.174526   \n",
       "495                  1  ...       0.248849       0.270873      -0.265309   \n",
       "496                  1  ...       0.104349       0.194024      -0.233074   \n",
       "497                  1  ...       0.485446       0.297390      -0.183910   \n",
       "\n",
       "     bert_emb_1529  bert_emb_1530  bert_emb_1531  bert_emb_1532  \\\n",
       "0        -0.252389      -0.000575       0.018712       0.063588   \n",
       "1        -0.228752       0.352128       0.289149       0.167564   \n",
       "2         0.173032       0.124249       0.041688       0.049730   \n",
       "3         0.296606       0.101162       0.226571       0.118238   \n",
       "4         0.037845       0.190290       0.199070       0.157979   \n",
       "..             ...            ...            ...            ...   \n",
       "493      -0.139512       0.258261      -0.041969       0.015981   \n",
       "494      -0.018774       0.112075       0.122162       0.169146   \n",
       "495      -0.511417      -0.054680      -0.045479       0.046454   \n",
       "496      -0.148121       0.062550       0.142849       0.004142   \n",
       "497      -0.026955       0.107112       0.228135      -0.238907   \n",
       "\n",
       "     bert_emb_1533  bert_emb_1534  bert_emb_1535  \n",
       "0        -0.332531       0.145222       0.176384  \n",
       "1        -0.207953       0.273443       0.123073  \n",
       "2        -0.416709       0.192840       0.117760  \n",
       "3        -0.580175       0.092836       0.090041  \n",
       "4        -0.535935       0.370099       0.298351  \n",
       "..             ...            ...            ...  \n",
       "493      -0.217825       0.524079       0.129853  \n",
       "494      -0.163527       0.422487       0.337666  \n",
       "495      -0.281854       0.048485       0.133614  \n",
       "496      -0.220661       0.132999      -0.114103  \n",
       "497      -0.309551       0.128129       0.237517  \n",
       "\n",
       "[498 rows x 1555 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>title_length</th>\n",
       "      <th>body_length</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>body_word_count</th>\n",
       "      <th>has_question_mark</th>\n",
       "      <th>...</th>\n",
       "      <th>bert_emb_1526</th>\n",
       "      <th>bert_emb_1527</th>\n",
       "      <th>bert_emb_1528</th>\n",
       "      <th>bert_emb_1529</th>\n",
       "      <th>bert_emb_1530</th>\n",
       "      <th>bert_emb_1531</th>\n",
       "      <th>bert_emb_1532</th>\n",
       "      <th>bert_emb_1533</th>\n",
       "      <th>bert_emb_1534</th>\n",
       "      <th>bert_emb_1535</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.747252e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1089</td>\n",
       "      <td>5</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327762</td>\n",
       "      <td>0.357278</td>\n",
       "      <td>-0.220949</td>\n",
       "      <td>-0.252389</td>\n",
       "      <td>-0.000575</td>\n",
       "      <td>0.018712</td>\n",
       "      <td>0.063588</td>\n",
       "      <td>-0.332531</td>\n",
       "      <td>0.145222</td>\n",
       "      <td>0.176384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.747258e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>1341</td>\n",
       "      <td>11</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419177</td>\n",
       "      <td>0.331732</td>\n",
       "      <td>-0.333891</td>\n",
       "      <td>-0.228752</td>\n",
       "      <td>0.352128</td>\n",
       "      <td>0.289149</td>\n",
       "      <td>0.167564</td>\n",
       "      <td>-0.207953</td>\n",
       "      <td>0.273443</td>\n",
       "      <td>0.123073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.747142e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>5252</td>\n",
       "      <td>15</td>\n",
       "      <td>773</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524374</td>\n",
       "      <td>0.305135</td>\n",
       "      <td>-0.026640</td>\n",
       "      <td>0.173032</td>\n",
       "      <td>0.124249</td>\n",
       "      <td>0.041688</td>\n",
       "      <td>0.049730</td>\n",
       "      <td>-0.416709</td>\n",
       "      <td>0.192840</td>\n",
       "      <td>0.117760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.747235e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>4172</td>\n",
       "      <td>10</td>\n",
       "      <td>656</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573908</td>\n",
       "      <td>0.084166</td>\n",
       "      <td>-0.433981</td>\n",
       "      <td>0.296606</td>\n",
       "      <td>0.101162</td>\n",
       "      <td>0.226571</td>\n",
       "      <td>0.118238</td>\n",
       "      <td>-0.580175</td>\n",
       "      <td>0.092836</td>\n",
       "      <td>0.090041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.746760e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>3435</td>\n",
       "      <td>14</td>\n",
       "      <td>616</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487628</td>\n",
       "      <td>0.455405</td>\n",
       "      <td>-0.368931</td>\n",
       "      <td>0.037845</td>\n",
       "      <td>0.190290</td>\n",
       "      <td>0.199070</td>\n",
       "      <td>0.157979</td>\n",
       "      <td>-0.535935</td>\n",
       "      <td>0.370099</td>\n",
       "      <td>0.298351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.747264e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>673</td>\n",
       "      <td>7</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.449083</td>\n",
       "      <td>0.395922</td>\n",
       "      <td>-0.337725</td>\n",
       "      <td>-0.139512</td>\n",
       "      <td>0.258261</td>\n",
       "      <td>-0.041969</td>\n",
       "      <td>0.015981</td>\n",
       "      <td>-0.217825</td>\n",
       "      <td>0.524079</td>\n",
       "      <td>0.129853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.747254e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1328</td>\n",
       "      <td>6</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477509</td>\n",
       "      <td>0.172439</td>\n",
       "      <td>-0.174526</td>\n",
       "      <td>-0.018774</td>\n",
       "      <td>0.112075</td>\n",
       "      <td>0.122162</td>\n",
       "      <td>0.169146</td>\n",
       "      <td>-0.163527</td>\n",
       "      <td>0.422487</td>\n",
       "      <td>0.337666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.747266e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>468</td>\n",
       "      <td>5</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248849</td>\n",
       "      <td>0.270873</td>\n",
       "      <td>-0.265309</td>\n",
       "      <td>-0.511417</td>\n",
       "      <td>-0.054680</td>\n",
       "      <td>-0.045479</td>\n",
       "      <td>0.046454</td>\n",
       "      <td>-0.281854</td>\n",
       "      <td>0.048485</td>\n",
       "      <td>0.133614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.747252e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>250</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104349</td>\n",
       "      <td>0.194024</td>\n",
       "      <td>-0.233074</td>\n",
       "      <td>-0.148121</td>\n",
       "      <td>0.062550</td>\n",
       "      <td>0.142849</td>\n",
       "      <td>0.004142</td>\n",
       "      <td>-0.220661</td>\n",
       "      <td>0.132999</td>\n",
       "      <td>-0.114103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.747252e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1925</td>\n",
       "      <td>9</td>\n",
       "      <td>339</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485446</td>\n",
       "      <td>0.297390</td>\n",
       "      <td>-0.183910</td>\n",
       "      <td>-0.026955</td>\n",
       "      <td>0.107112</td>\n",
       "      <td>0.228135</td>\n",
       "      <td>-0.238907</td>\n",
       "      <td>-0.309551</td>\n",
       "      <td>0.128129</td>\n",
       "      <td>0.237517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows × 1555 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T21:38:36.745336Z",
     "start_time": "2025-06-14T21:38:36.075951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Step 1: Prepare your data\n",
    "X = data_combined.drop(\"market_viability\", axis=1)  # Replace \"target\" if your column has a different name\n",
    "y = data_combined[\"market_viability\"]\n",
    "\n",
    "neg = (y == 0).sum()\n",
    "pos = (y == 1).sum()\n",
    "scale_pos_weight = neg / pos\n",
    "\n",
    "# Step 2: Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Apply SMOTE to training data only\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 3: Train the XGBoost classifier\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42\n",
    ")\n",
    "xgb_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Step 4: Evaluate\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ],
   "id": "b87af5d273f4d906",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'line_search_wolfe1' from 'sklearn.utils.fixes' (C:\\Users\\josep\\OneDrive\\Desktop\\Software\\RedditProblemFinder\\.venv\\Lib\\site-packages\\sklearn\\utils\\fixes.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[57]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mimblearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mover_sampling\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SMOTE\n\u001B[32m      3\u001B[39m \u001B[38;5;66;03m# Step 1: Prepare your data\u001B[39;00m\n\u001B[32m      4\u001B[39m X = data_combined.drop(\u001B[33m\"\u001B[39m\u001B[33mmarket_viability\u001B[39m\u001B[33m\"\u001B[39m, axis=\u001B[32m1\u001B[39m)  \u001B[38;5;66;03m# Replace \"target\" if your column has a different name\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Software\\RedditProblemFinder\\.venv\\Lib\\site-packages\\imblearn\\__init__.py:52\u001B[39m\n\u001B[32m     48\u001B[39m     sys.stderr.write(\u001B[33m\"\u001B[39m\u001B[33mPartial import of imblearn during the build process.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     49\u001B[39m     \u001B[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001B[39;00m\n\u001B[32m     50\u001B[39m     \u001B[38;5;66;03m# process, as it may not be compiled yet\u001B[39;00m\n\u001B[32m     51\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m52\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     53\u001B[39m         combine,\n\u001B[32m     54\u001B[39m         ensemble,\n\u001B[32m     55\u001B[39m         exceptions,\n\u001B[32m     56\u001B[39m         metrics,\n\u001B[32m     57\u001B[39m         over_sampling,\n\u001B[32m     58\u001B[39m         pipeline,\n\u001B[32m     59\u001B[39m         tensorflow,\n\u001B[32m     60\u001B[39m         under_sampling,\n\u001B[32m     61\u001B[39m         utils,\n\u001B[32m     62\u001B[39m     )\n\u001B[32m     63\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_version\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m __version__\n\u001B[32m     64\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbase\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m FunctionSampler\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Software\\RedditProblemFinder\\.venv\\Lib\\site-packages\\imblearn\\combine\\__init__.py:5\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[33;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[33;03mover-sampling and under-sampling.\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_smote_enn\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SMOTEENN\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_smote_tomek\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SMOTETomek\n\u001B[32m      8\u001B[39m __all__ = [\u001B[33m\"\u001B[39m\u001B[33mSMOTEENN\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mSMOTETomek\u001B[39m\u001B[33m\"\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Software\\RedditProblemFinder\\.venv\\Lib\\site-packages\\imblearn\\combine\\_smote_enn.py:12\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbase\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m clone\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m check_X_y\n\u001B[32m---> \u001B[39m\u001B[32m12\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbase\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BaseSampler\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mover_sampling\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SMOTE\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mover_sampling\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbase\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BaseOverSampler\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Software\\RedditProblemFinder\\.venv\\Lib\\site-packages\\imblearn\\base.py:15\u001B[39m\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_metadata_requests\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m METHODS\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmulticlass\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m check_classification_targets\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m check_sampling_strategy, check_target_type\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_sklearn_compat\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _fit_context, get_tags, validate_data\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_validation\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ArraysTransformer\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Software\\RedditProblemFinder\\.venv\\Lib\\site-packages\\imblearn\\utils\\__init__.py:6\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[33;03mThe :mod:`imblearn.utils` module includes various utilities.\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_docstring\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Substitution\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_validation\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m      7\u001B[39m     check_neighbors_object,\n\u001B[32m      8\u001B[39m     check_sampling_strategy,\n\u001B[32m      9\u001B[39m     check_target_type,\n\u001B[32m     10\u001B[39m )\n\u001B[32m     12\u001B[39m __all__ = [\n\u001B[32m     13\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mcheck_neighbors_object\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     14\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mcheck_sampling_strategy\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     15\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mcheck_target_type\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     16\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mSubstitution\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     17\u001B[39m ]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Software\\RedditProblemFinder\\.venv\\Lib\\site-packages\\imblearn\\utils\\_validation.py:15\u001B[39m\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mscipy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msparse\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m issparse\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbase\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m clone\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mneighbors\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m NearestNeighbors\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m column_or_1d\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmulticlass\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m type_of_target\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Software\\RedditProblemFinder\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\__init__.py:18\u001B[39m\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_kde\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m KernelDensity\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_lof\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m LocalOutlierFactor\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_nca\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m NeighborhoodComponentsAnalysis\n\u001B[32m     19\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_nearest_centroid\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m NearestCentroid\n\u001B[32m     20\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_regression\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m KNeighborsRegressor, RadiusNeighborsRegressor\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Software\\RedditProblemFinder\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_nca.py:22\u001B[39m\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mscipy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01moptimize\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m minimize\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbase\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     17\u001B[39m     BaseEstimator,\n\u001B[32m     18\u001B[39m     ClassNamePrefixFeaturesOutMixin,\n\u001B[32m     19\u001B[39m     TransformerMixin,\n\u001B[32m     20\u001B[39m     _fit_context,\n\u001B[32m     21\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m22\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdecomposition\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m PCA\n\u001B[32m     23\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mexceptions\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ConvergenceWarning\n\u001B[32m     24\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmetrics\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m pairwise_distances\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Software\\RedditProblemFinder\\.venv\\Lib\\site-packages\\sklearn\\decomposition\\__init__.py:11\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;66;03m# Authors: The scikit-learn developers\u001B[39;00m\n\u001B[32m      8\u001B[39m \u001B[38;5;66;03m# SPDX-License-Identifier: BSD-3-Clause\u001B[39;00m\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mextmath\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m randomized_svd\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_dict_learning\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     12\u001B[39m     DictionaryLearning,\n\u001B[32m     13\u001B[39m     MiniBatchDictionaryLearning,\n\u001B[32m     14\u001B[39m     SparseCoder,\n\u001B[32m     15\u001B[39m     dict_learning,\n\u001B[32m     16\u001B[39m     dict_learning_online,\n\u001B[32m     17\u001B[39m     sparse_encode,\n\u001B[32m     18\u001B[39m )\n\u001B[32m     19\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_factor_analysis\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m FactorAnalysis\n\u001B[32m     20\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_fastica\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m FastICA, fastica\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Software\\RedditProblemFinder\\.venv\\Lib\\site-packages\\sklearn\\decomposition\\_dict_learning.py:21\u001B[39m\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mscipy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m linalg\n\u001B[32m     15\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbase\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     16\u001B[39m     BaseEstimator,\n\u001B[32m     17\u001B[39m     ClassNamePrefixFeaturesOutMixin,\n\u001B[32m     18\u001B[39m     TransformerMixin,\n\u001B[32m     19\u001B[39m     _fit_context,\n\u001B[32m     20\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m21\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mlinear_model\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Lars, Lasso, LassoLars, orthogonal_mp_gram\n\u001B[32m     22\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m check_array, check_random_state, gen_batches, gen_even_slices\n\u001B[32m     23\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_param_validation\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Interval, StrOptions, validate_params\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Software\\RedditProblemFinder\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\__init__.py:24\u001B[39m\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_bayes\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ARDRegression, BayesianRidge\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_coordinate_descent\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     13\u001B[39m     ElasticNet,\n\u001B[32m     14\u001B[39m     ElasticNetCV,\n\u001B[32m   (...)\u001B[39m\u001B[32m     22\u001B[39m     lasso_path,\n\u001B[32m     23\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m24\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_glm\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m GammaRegressor, PoissonRegressor, TweedieRegressor\n\u001B[32m     25\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_huber\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m HuberRegressor\n\u001B[32m     26\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_least_angle\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     27\u001B[39m     Lars,\n\u001B[32m     28\u001B[39m     LarsCV,\n\u001B[32m   (...)\u001B[39m\u001B[32m     33\u001B[39m     lars_path_gram,\n\u001B[32m     34\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Software\\RedditProblemFinder\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\__init__.py:4\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Authors: The scikit-learn developers\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;66;03m# SPDX-License-Identifier: BSD-3-Clause\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mglm\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m      5\u001B[39m     GammaRegressor,\n\u001B[32m      6\u001B[39m     PoissonRegressor,\n\u001B[32m      7\u001B[39m     TweedieRegressor,\n\u001B[32m      8\u001B[39m     _GeneralizedLinearRegressor,\n\u001B[32m      9\u001B[39m )\n\u001B[32m     11\u001B[39m __all__ = [\n\u001B[32m     12\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33m_GeneralizedLinearRegressor\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     13\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mPoissonRegressor\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     14\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mGammaRegressor\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     15\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mTweedieRegressor\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     16\u001B[39m ]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Software\\RedditProblemFinder\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:24\u001B[39m\n\u001B[32m     22\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_openmp_helpers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _openmp_effective_n_threads\n\u001B[32m     23\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_param_validation\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Hidden, Interval, StrOptions\n\u001B[32m---> \u001B[39m\u001B[32m24\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01moptimize\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _check_optimize_result\n\u001B[32m     25\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mvalidation\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _check_sample_weight, check_is_fitted, validate_data\n\u001B[32m     26\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_linear_loss\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m LinearModelLoss\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Software\\RedditProblemFinder\\.venv\\Lib\\site-packages\\sklearn\\utils\\optimize.py:24\u001B[39m\n\u001B[32m     21\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mscipy\u001B[39;00m\n\u001B[32m     23\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mexceptions\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ConvergenceWarning\n\u001B[32m---> \u001B[39m\u001B[32m24\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfixes\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m line_search_wolfe1, line_search_wolfe2\n\u001B[32m     27\u001B[39m \u001B[38;5;28;01mclass\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m_LineSearchError\u001B[39;00m(\u001B[38;5;167;01mRuntimeError\u001B[39;00m):\n\u001B[32m     28\u001B[39m     \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "\u001B[31mImportError\u001B[39m: cannot import name 'line_search_wolfe1' from 'sklearn.utils.fixes' (C:\\Users\\josep\\OneDrive\\Desktop\\Software\\RedditProblemFinder\\.venv\\Lib\\site-packages\\sklearn\\utils\\fixes.py)"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dfb6817ad60d89d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
